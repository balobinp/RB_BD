{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from pandas import Series, DataFrame\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "from os.path import join, normpath\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "downloads = 'C:/Users/balob/Downloads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balob\\Documents\\GITLAB\\RB_BD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/balob/Documents/GITLAB/RB_BD')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path_dir = Path.cwd()\n",
    "print(path_dir)\n",
    "path_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from MS SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Из базы данных OCS выгружаем TADIG\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc \n",
    "#Connect to OCSDBREP1 (BSS)\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=172.18.11.82;DATABASE=10028;UID=BSS;PWD=iKQVm40AZAmyRaw72LeY')\n",
    "\n",
    "sql_srt=\\\n",
    "'''\n",
    "SELECT DISTINCT mcc.mcc,c.country_name FROM RDB_NETWORK_IMSI_PREFIXES mcc\n",
    "LEFT JOIN RDB_NETWORKS net\n",
    "ON mcc.NETWORK_ID=net.NETWORK_ID\n",
    "LEFT JOIN RDB_COUNTRIES c\n",
    "ON c.country_id=net.country_id\n",
    "'''\n",
    "\n",
    "df_tadig = pd.read_sql_query(sql_srt, cnxn, coerce_float=False)\n",
    "#df_tadig['TADIG_CODE_ID']=df_tadig['TADIG_CODE_ID'].astype('int')\n",
    "#df_tadig['NETWORK_ID']=df_tadig['NETWORK_ID'].astype('int')\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from Maria DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector #pip install mysql-connector-python-rf\n",
    "import pandas as pd\n",
    "\n",
    "cnxn = mysql.connector.connect(user='noc', password='WcQUzkXiXwoxnFfGnRxb',host='172.18.11.40',database='BSS')\n",
    "\n",
    "sql_srt=\\\n",
    "'''\n",
    "SELECT\n",
    "VisitedNetworkTadig\n",
    ",CostTariffId\n",
    ",MIN((Cost*1024*1024)/TotalChargedUnits) AS Price_min\n",
    ",AVG((Cost*1024*1024)/TotalChargedUnits) AS Price_avg\n",
    ",STDDEV_SAMP((Cost*1024*1024)/TotalChargedUnits) AS Price_std\n",
    ",MAX((Cost*1024*1024)/TotalChargedUnits) AS Price_max\n",
    "FROM TAP.GPRS_CALL\n",
    "WHERE\n",
    "TreatedTimestampUtc > 20180810000000\n",
    "AND VisitedNetworkTadig = 'BHSBH'\n",
    "GROUP BY VisitedNetworkTadig,CostTariffId\n",
    "'''\n",
    "\n",
    "df_mariadb = pd.read_sql_query(sql_srt, cnxn)\n",
    "\n",
    "cnxn.close()\n",
    "df_mariadb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soap API OCS Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to Reseller: WMB Limited RT.    \n",
      "Available credit for the Reseller: 643 USD.\n",
      "\n",
      "The Reseller contains the following accounts:\n",
      " 0    WM&B Limited Test SIM (accountID: 352496)\n",
      " 1    WMB 5K Simcards order (accountID: 352537)\n",
      " 2    Hoang Tran (accountID: 352541)\n",
      " 3    Test1 (accountID: 352542)\n",
      " 4    Test2 (accountID: 352543)\n"
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "from zeep import Client\n",
    "from zeep.wsse.username import UsernameToken\n",
    "\n",
    "connect = 'prod' #'prod' or 'lab'\n",
    "\n",
    "if connect == 'lab':\n",
    "    user = 'lab_api@roamability.com'\n",
    "    password = '25D55AD283AA400AF464C76D713C07AD' #Lab\n",
    "    #api_link = 'https://172.20.39.7:8585/ocsapi/roamability/api/roamability.wsdl' #Lab\n",
    "    api_link = 'https://labocsapi.roamability.com:6443/ocsapi/roamability/api/roamability.wsdl'\n",
    "elif connect == 'prod':\n",
    "    user = 'prod_api@roamability.com'\n",
    "    password = '25D55AD283AA400AF464C76D713C07AD'\n",
    "    api_link = 'http://172.20.35.12:8585/ocsapi/roamability/api/roamability.wsdl'\n",
    "\n",
    "user_name_token = UsernameToken(user, password)\n",
    "user_name_token.use_digest = True\n",
    "client = Client(api_link, wsse=user_name_token)\n",
    "\n",
    "reseller = client.service.getResellerInfo()\n",
    "accounts = client.service.getAccounts()\n",
    "\n",
    "if reseller.result.code == '1':\n",
    "    print('You are connected to Reseller: {}.\\\n",
    "    \\nAvailable credit for the Reseller: {:.0f} USD.\\n'.\\\n",
    "    format(reseller.reseller.resellerName,reseller.reseller.availableCredit))\n",
    "else:\n",
    "    print('Error in getting Reseller info: {}'.format(reseller.result.description))\n",
    "\n",
    "if accounts.result.code == '1':\n",
    "    accounts_dict = {account.accountId:account.accountName for account in accounts.accounts.accounts}\n",
    "    print('The Reseller contains the following accounts:')\n",
    "    for i,[account_id,account_name] in enumerate(accounts_dict.items()):\n",
    "        print(' {:<5}{} (accountID: {})'.format(i,account_name,account_id))\n",
    "else:\n",
    "    print('Error in getting Account info: {}'.format(accounts.result.description))\n",
    "    \n",
    "# Subscriber in lab in STI account\n",
    "#subscriber_id = client.service.getSubscriberById('934311')\n",
    "#subscriber_iccid = client.service.getSubscriberByICCID('8997219121000031446')\n",
    "#subscriber_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    'result': {\n",
       "        'code': '6',\n",
       "        'description': 'Internal error',\n",
       "        'errorUUID': 'cb1fa827-c1b7-4456-8388-888b6174f946'\n",
       "    },\n",
       "    'subscriber': None\n",
       "}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscriber_imsi = client.service.getSubscriberByIMSI('425019613026594')\n",
    "subscriber_imsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing DMI Steering API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://roamdb.roamability.com/SteeringAPI/Test'\n",
    "payload = {'SponsorIMSI':'425019613990511',\n",
    "           'RealIMSI':'425019613990511',\n",
    "           'Mcc':'262',\n",
    "           'SessionID':'1234567'}\n",
    "response = requests.post(url,payload)\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "net_list = []\n",
    "for net in soup.find_all('Network'):\n",
    "    net_list.append([net.Rank.text,net.Mcc.text,net.Mnc.text,net.Name.text,net.Support4G.text,net.Discounted.text,net.Cost.text])\n",
    "DataFrame(net_list,columns=['Rank','MCC','MNC','Operator_name','4G_Support','Discounted','Cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send MSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http\n",
    "import re\n",
    "\n",
    "ss7_url = \"172.18.11.10\"\n",
    "ss7_path = \"/cgi-bin/ss7gw.fcgi\"\n",
    "\n",
    "def executeHTTP(request, url, path):\n",
    "    client = http.client.HTTPConnection(url)\n",
    "    client.request(\"POST\", path, request, {\"Content-Type\" : \"text/xml\"})\n",
    "    resp = client.getresponse()    \n",
    "    return resp.read()\n",
    "\n",
    "def sri4sm(ogt, msisdn):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "        <ss7gw request=\\\"SRI_SM\\\">\n",
    "        <d_ssn>6</d_ssn>\n",
    "        <o_ssn>8</o_ssn>\n",
    "        <o_gt>%s</o_gt>\n",
    "        <d_gt>%s</d_gt>\n",
    "        <msisdn>%s</msisdn>\n",
    "        <priority>1</priority>\n",
    "        <address>%s</address>\n",
    "        </ss7gw>\"\"\" % (ogt, msisdn, msisdn, ogt)\n",
    "    \n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def prn(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"PRN\\\">\n",
    "          <d_ssn>7</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>6</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <password>123</password>\n",
    "          <msc_number>%s</msc_number>\n",
    "          <gmsc_addr>%s</gmsc_addr>\n",
    "          <map>3</map>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi, dgt, ogt)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def sai(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"SAIN\\\">\n",
    "          <d_ssn>6</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>7</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <num_req_vec>1</num_req_vec>\n",
    "          <sccp_np>7</sccp_np>\n",
    "          <node_type>0</node_type>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "#sri4sm_resp = sri4sm('8526450105110', '85264573236')\n",
    "#sri4sm_resp = sri4sm('66893773228', '66893100528')\n",
    "\n",
    "#soup = BeautifulSoup( sri4sm('447797706411', '66893773203'),'xml' )\n",
    "soup = BeautifulSoup( sai('447797706411', '668930180000000', '520150180000000'),'xml' )\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "print( 'start: {} {} :end'.format('one', 'two') ) #start: one two :end\n",
    "print( 'start: {1} {0} :end'.format('one', 'two') ) #start: two one :end\n",
    "print( 'start: test {:10} :end'.format('test') ) #start: test test       :end\n",
    "print( 'start: test {:10} :end'.format(10) ) #start: test         10 :end\n",
    "print( 'start: test {:>10} :end'.format('test') ) #start: test       test :end\n",
    "print( 'start: test {:<10} :end'.format('test') ) #start: test test       :end\n",
    "print( 'start: test {:_<10} :end'.format('test') ) #start: test test______ :end\n",
    "print( 'start: test {:^10} :end'.format('test') ) #start: test    test    :end\n",
    "print( 'start: test {:.10} :end'.format('test1test2test3') ) #start: test test1test2 :end\n",
    "print( 'start: test {:_^10.5} :end'.format('test1test2test3') ) #start: test __test1___ :end\n",
    "print( 'start: test {:d} :end'.format(42) ) #start: test 42 :end\n",
    "print( 'start: test {:f} :end'.format(42) ) #start: test 42.000000 :end\n",
    "print( 'start: test {:06.2f} :end'.format(3.141592) ) #start: test 003.14 :end\n",
    "print( 'start: test {p[first]} {p[last]} :end'.format(p={'first': 'Jean-Luc', 'last': 'Picard'}) ) #start: test Jean-Luc Picard :end\n",
    "print( 'start: test {p[4]} {p[5]} :end'.format(p=[4, 8, 15, 16, 23, 42]) ) #start: test 23 42 :end\n",
    "print( 'start: test {:%Y-%m-%d %H:%M} :end'.format(dt.datetime(2001, 2, 3, 4, 5)) ) #start: test 2001-02-03 04:05 :end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame\n",
    "df=DataFrame(np.arange(200,212).reshape((3,4)) ,columns=list('abcd'),index=pd.date_range(start='1/1/2000 00:00:00',periods=3,freq='1H'))\n",
    "df=DataFrame(np.arange(200,212).reshape((3,4)) ,columns=list('abcd'))\n",
    "df=DataFrame(np.arange(200,212).reshape((3,4)) ,columns=list('abcd'),index=['Utah','Ohio','Texas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV\n",
    "df_tadig = pd.read_csv('TADIG.csv',sep=';',header=None,dtype={'MCC':object,'MNC':object},\n",
    "                   names=['TADIG','MCC','MNC'],skiprows=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вариант №1\n",
    "#Группировка с применением различных типов агрегации к колонкам groupby().agg\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=DataFrame({'data1':np.random.randint(0,10,size=20),'data2':np.random.randint(0,10,size=20),\n",
    "              'key1':list('abcd'*5),'key2':list('fghi'*5)},index=([list('klmno'*4),list('pq'*10)]))\n",
    "df.index.names=['ind1','ind2']\n",
    "df.columns.names=['col_info']\n",
    "df.groupby(['key1']).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одной колонке (вариант 1 задания группировки)\n",
    "df.groupby(df['key1']).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одной колонке (вариант 2 задания группировки)\n",
    "df.groupby(df['key1']).agg({'data1': [np.min,np.mean,np.max,np.size], 'data2': [np.min,np.mean,np.max,np.size]}) #Агрегация для каждого поля несколько функций\n",
    "df.groupby(df['key1']).agg({'data1': [('f_min',np.min),('f_max',np.max)],'data2': [('f_min',np.min),('f_max',np.max)]}) #Агрегация для каждого поля несколько функций с переименованием\n",
    "df.groupby(['key1','key2']).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по нескольким колонкам\n",
    "df.groupby(level=0).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одному индексу (вариант 1 указания индекса)\n",
    "df.groupby(level='ind1').agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одному индексу (вариант 2 указания индекса)\n",
    "df.groupby(level=[0,1]).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по нескольким индексам\n",
    "df[['data1','data2']].groupby(level=[0,1]).agg(['min','max']) #Агрегация для каждого поля несколько функций\n",
    "df[['data1','data2']].groupby(level=[0,1]).agg([('fmin','min'),('fmax','max')]) #Агрегация для каждого поля несколько функций с переименованием\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вариант №3\n",
    "#Группировка .groupby + агрегирующая функция\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=DataFrame({'data1':np.random.randint(0,10,size=20),'data2':np.random.randint(0,10,size=20),\n",
    "              'key1':list('abcd'*5),'key2':list('fghi'*5)},index=([list('klmno'*4),list('pq'*10)]))\n",
    "df.index.names=['ind1','ind2']\n",
    "df.columns.names=['col_info']\n",
    "\n",
    "# The Best Practice\n",
    "df.groupby(['key1'],as_index=False)['data1'].max()\n",
    "df.groupby(level=0)['data1'].max().reset_index()\n",
    "\n",
    "df['data1'].groupby(df['key1']).mean() #Агрегация одного поля по одному ключу\n",
    "df.groupby(df['key1']).mean() #Агрегация всех полей по одному ключу\n",
    "df[['data1','data2']].groupby(df['key1']).mean() #Агрегация нескольких полей по одному ключу\n",
    "df[['data1','data2']].groupby([df['key1'],df['key2']]).mean() #Агрегация нескольких полей по нескольким ключам\n",
    "df[['data1','data2']].groupby(level=0).mean() #Агрегация по одному индексу (вариант 1 указания индекса)\n",
    "df[['data1','data2']].groupby(level='ind1').mean() #Агрегация по одному индексу (вариант 2 указания индекса)\n",
    "df[['data1','data2']].groupby(level=[0,1]).mean() #Агрегация по нескольким индексам\n",
    "df[['data1','data2']].groupby(level=0,axis=1).mean() #Агрегация с группировкой по столбцам\n",
    "#или\n",
    "grouped=df['data1'].groupby(df['key1'])\n",
    "grouped.mean()\n",
    "#или\n",
    "df.groupby(df['key1'])['data1'].mean()\n",
    "#Чтобы добавить префикс к названию строки/столбца\n",
    "#df['data1'].groupby(df['key1']).mean().add_prefix('mean_')\n",
    "#df[['data1','data2']].groupby(level=0,axis=1).mean()\n",
    "df['data1_mean']=df.groupby('key1')['data1'].transform(np.max)\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in Allowed Lists and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like expression for Allowed List\n",
    "df_al=pd.read_csv(join(downloads,'DMI.dmi_allowed_list_export_Sun_Dec_09_2018.csv'))\n",
    "#df_al_lab=pd.read_csv('LAB_DMI.dmi_allowed_list_export_Wed_Oct_03_2018.csv')\n",
    "\n",
    "#df_dmi_diam_oper=pd.read_csv(join(download,''))\n",
    "df_np=pd.read_csv(join(downloads,'DMI.dmi_netpfx_export_Tue_Oct_30_2018.csv'))\n",
    "#df_did=pd.read_csv('HRR.hrr_did_export_Wed_Aug_08_2018.csv')\n",
    "#f_tap_ocs=pd.read_csv('tap_ocs_analysis_180817.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sponsor</th>\n",
       "      <th>PLMN code</th>\n",
       "      <th>MO</th>\n",
       "      <th>MT</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Data</th>\n",
       "      <th>MO.1</th>\n",
       "      <th>sec</th>\n",
       "      <th>Data.1</th>\n",
       "      <th>kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>P4_mon_world</td>\n",
       "      <td>RUSBD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sponsor PLMN code  MO  MT  SMS  Data  MO.1  sec  Data.1   kb\n",
       "3345  P4_mon_world     RUSBD   1   1    1     1     1    1     NaN  NaN"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_al[(df_al['PLMN code'].str.startswith('MKDCC', na=False)) & (df_al['Sponsor']=='')]\n",
    "df_al[(df_al['PLMN code'].str.startswith('LAOLA', na=False)) & (df_al['Sponsor'].str.contains('', na=False))]\n",
    "#VENMS_IDNTS_CHLTM_NGAET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df_np[df_np.Operator == ''].Prefix.unique().tolist())\n",
    "df_np[(df_np.Operator.str.startswith('GTMCM',na=False))&(df_np.SSN==7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np[(df_np.Prefix.str.startswith('49175052',na=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dmi_diam_oper[(df_dmi_diam_oper['DMI Operator'].str.startswith('', na=False))\\\n",
    "                 & (df_dmi_diam_oper['Realm'].str.contains('405', na=False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in ALARMS by folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/W_DATA_ROAM/ALARMS/UL_LAOLA_181102_#2003596']"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = 'c:/W_DATA_ROAM/ALARMS/'\n",
    "#path = 'c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/PRICES/'\n",
    "#path = c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\\n",
    "#path = 'c:/W_DATA_ROAM/ПРОЕКТЫ/'\n",
    "#path = 'c:/W_DATA_ROAM_DOC/ПРОЕКТЫ/'\n",
    "names = os.listdir(path)\n",
    "[path + name for name in names if name.upper().find('LAOLA')!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in files by Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\OCS_Trigger_for_Nextel.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#ocs_principle_of_operation\n",
      "#ocs_mop\n",
      "#activation_principle_of_operation\n",
      "#nextel_principle_of_operation\n",
      "------------------------------\n",
      "МОР по добавлению триггера для Nextel.\n",
      "При активации абонента будет автоматически устанавливаться INT_PRICING_PLAN.\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\activation_principle_of_operation\\_TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#dmi_ocs_principle_of_operation\n",
      "#dmi_principle_of_operation\n",
      "#ocs_principle_of_operation\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "Описание принципа активации абонента при нажатии кнопки «Add Multi IMSI» в OCS\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\Add_IMSI_on_the_fly_Example\\_TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#steering_principle_of_operation\n",
      "#activation_principle_of_operation\n",
      "#dmi_principle_of_operation\n",
      "#ocs_principle_of_operation\n",
      "#dmi_ocs_principle_of_operation\n",
      "------------------------------\n",
      "Пример добавления IMSI on the fly\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\SIM_Reader\\_TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "\"Any PCSC reader can be used. I have good experience with ACS (https://www.acs.com.hk/) and OMNIKEY (https://www.hidglobal.com/products/readers/omnikey) readers.\"\n",
      "(https://roamability.teamwork.com/#/tasks/12118095)\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\МЕТОДИКИ\\M_Change_SQN_in_AUC\\_TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "Как менять ключи в AUC.\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\МЕТОДИКИ\\M_OCS_SUB_CREATOR\\_TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#ocs_mop\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "Программа Роя, создающая абонентов в OCS базе данных\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ПРОЕКТЫ\\TROUBLE_DMI_Timeouts\\readme.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#known_issue\n",
      "#dmi_principle_of_operation\n",
      "#dmi_ocs_principle_of_operation\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "\"у нас две разные проблемы с таймаутами\n",
      "Первая - SOAP таймаут затрагивает обычную активацию и fly IMSI активацию\n",
      "\n",
      "Вторая - проблема с доставкой TCP сообщений в OCS\n",
      "\n",
      "Первую проблему нужно долго и внимательно исследовать. Вторая проще - нужно посмотреть трейсы TCP и определить место где теряется сообщение\"\n",
      "(Владимир И., Skype, 25.10.2018)\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_M_NEW_CONNECTION\\015_SIM_IMSI_Provisioning\\readme.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#sim_card_mop\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "Для того, чтобы залить аплет на SIM нужны ключи.\n",
      "Например, для Cellact:\n",
      "425180000009058 425180000009058 8997209700000090582 7880 71304162 8105 81721507 A0AB44F3 91D68FA14A3076656DE959C75A3F7944 6F4A4A8908B7EB4A23EB308C278148CD 6123F2AE6E3D085FF4F7E79F885F911C 85AB1AD455F694FD7A9F24C1C19EF44E BABFFC45ACAF20C1EDB9DC7D1A78ABE9\n",
      "4\n",
      "Var_Out: IMSI/IMSI2/ICCID/PIN1/PUK1/PIN2/PUK2/ADM1/KI/KIC/KID/KIK/KIKA\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ALARMS\\ACT_Subscriber_Created_in_DMI_not_OCS\\_TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#dmi_ocs_principle_of_operation\n",
      "#known_issue\n",
      "#activation_principle_of_operation\n",
      "------------------------------\n",
      "Проблема с абонентами, которые прописаны в DMI, но отсутствуют в OCS (нет ни одного IMSI).\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ALARMS\\OCS_provisioning_issue\\readme.txt\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, isdir, join, normpath\n",
    "from tqdm import tqdm\n",
    "\n",
    "paths = ['c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/NOC_HOW_IT_WORKS/',\n",
    "        'c:/W_DATA_ROAM/МЕТОДИКИ/',\n",
    "        'c:/W_DATA_ROAM/ПРОЕКТЫ/',\n",
    "        'c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/NOC_KNOWN_ISSUES/',\n",
    "         'c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/NOC_M_NEW_CONNECTION/',\n",
    "        'c:/W_DATA_ROAM/ALARMS/']\n",
    "\n",
    "# Если хотя бы один из тэгов присутствует. Нужно указать хотя бы один.\n",
    "any_tags  = ['#activation_principle_of_operation']\n",
    "# Если все теги присутствуют. Можно указать [] если нет обязательных тэгов.\n",
    "all_tags = []\n",
    "\n",
    "def find_txt_files_and_folders(path_name):\n",
    "    file_names_all = os.listdir(path_name)\n",
    "    files = [file for file in file_names_all if isfile(join(path_name, file)) if file.find('.txt')!=-1]\n",
    "    folders = [folder for folder in file_names_all if isdir(join(path, folder))]\n",
    "    return files,folders\n",
    "\n",
    "def search_tags_in_file(path_name,files_list):\n",
    "    for file in files_list:\n",
    "        with open(join(path_name, file)) as inf:\n",
    "            # Преобразовать файл в список. В качествер разделителя пробел. read читает весь файл.\n",
    "            words_in_file = inf.read().lower().split()\n",
    "        if any(item in words_in_file for item in any_tags):\n",
    "            if len(all_tags) > 0 and all(item in words_in_file for item in all_tags):\n",
    "                print_description_from_file(path_name,file)\n",
    "            elif len(all_tags) == 0:               \n",
    "                print_description_from_file(path_name,file)\n",
    "    return None\n",
    "\n",
    "def print_description_from_file(path_name,file_name):\n",
    "    print(100*'*')\n",
    "    print(normpath(join(path_name, file_name)))\n",
    "    print(100*'-')\n",
    "    with open(join(path_name, file_name)) as inf:\n",
    "        # Построчно читаем файл\n",
    "        # Процедура неотимальна, т.к. будет прочитан весь файл до конца\n",
    "        for line in inf:\n",
    "            line.strip()\n",
    "            if '<DESCRIPTION>' in line:\n",
    "                for line in inf:\n",
    "                    line.strip()\n",
    "                    if '</DESCRIPTION>' in line:\n",
    "                        print('')\n",
    "                        break\n",
    "                    else:\n",
    "                        print(line,end='')\n",
    "            elif '<TAGS>' in line:\n",
    "                for line in inf:\n",
    "                    line.strip()\n",
    "                    if '</TAGS>' in line:\n",
    "                        print(30*'-')\n",
    "                        break\n",
    "                    else:\n",
    "                        print(line,end='')\n",
    "    return None\n",
    "\n",
    "for path in paths:\n",
    "    files,folders = find_txt_files_and_folders(path)\n",
    "    search_tags_in_file(path,files)\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_path = join(path, folder)\n",
    "        files,_ = find_txt_files_and_folders(folder_path)\n",
    "        search_tags_in_file(folder_path,files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex to Dec conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('f91e',16)\n",
    "hex(11025)\n",
    "int('2911',16)\n",
    "int('11111111111111111111111111111111',2)\n",
    "bin(65432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b10001000101\n",
      "0 - 136 - 5\n"
     ]
    }
   ],
   "source": [
    "print(bin(1093))\n",
    "a = '00010001000101'\n",
    "# = '00000011001101'\n",
    "print(int(a[-14:-11],2),'-',int(a[-11:-3],2),'-',int(a[-3:],2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "path = 'c:/Users/balob/Downloads/new1/'\n",
    "prefix = 'PYCON'\n",
    "topic = ''\n",
    "os.chdir(path)\n",
    "names = sorted(filter(os.path.isfile, os.listdir('.')), key=os.path.getmtime)\n",
    "for i,name in enumerate(names):\n",
    "    short_name = re.sub('[!#?«»,() \\+\\-؟]','',name[:-4:][:50])\n",
    "    if i < 10:\n",
    "        number = '0'+str(i)\n",
    "    else:\n",
    "        number = str(i)\n",
    "    new_name = '{}_{}_{}.mp4'.format(prefix,number,short_name)\n",
    "    print('{} -> {}'.format(name,new_name))\n",
    "    os.rename(name,new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение логов с удаленного сервера SFTP (stat_GrayLog.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2018-12-14 05:00:45,537 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:44.009712\n",
      "8 2018-12-13 05:00:45,731 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:43.732656\n",
      "16 2018-12-12 05:00:44,040 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:42.703231\n",
      "24 2018-12-11 05:00:41,949 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:39.759998\n",
      "32 2018-12-10 05:00:42,655 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:40.982727\n",
      "40 2018-12-09 05:00:46,048 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:42.357029\n",
      "48 2018-12-08 05:00:44,158 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:42.308123\n"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "print_lines = 50\n",
    "host = '172.19.11.191'\n",
    "user = 'pavel'\n",
    "secret = 'RzAZPjMjvujCPjU88bpevQp'\n",
    "file_path_name = '/home/tracer/LOG/stat_GrayLog.log'\n",
    "port = 22\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(hostname=host, username=user, password=secret, port=port)\n",
    "sftp_client = client.open_sftp()\n",
    "remote_file = sftp_client.open(file_path_name)\n",
    "try:\n",
    "    #for line in remote_file:\n",
    "    for i,line in enumerate(reversed(list(remote_file))):\n",
    "        if i < print_lines:\n",
    "            if 'Total' in line:\n",
    "                print(i,line,end='')\n",
    "            #print(i,line,end='')\n",
    "        else:\n",
    "            break\n",
    "finally:\n",
    "    remote_file.close()\n",
    "client.close()\n",
    "# (https://stackoverflow.com/questions/1596963/read-a-file-from-server-with-ssh-using-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc=0.144\n",
    "mtc=0\n",
    "text=0.19\n",
    "data=0.0672749999999999\n",
    "\n",
    "tariff=[moc,mtc,text,data]\n",
    "\n",
    "print(\"Price P4\")\n",
    "for k,v in {'1.2':1.2,'1.2*1.5':1.2*1.5,'1.2*1.5*1.15':1.2*1.5*1.15,'1.2*1.5*1.30':1.2*1.5*1.30,'2':1.2*2}.items():\n",
    "    print(\"Price {:<15}:\".format(k),[round(i*v,6) for i in tariff])\n",
    "print(\"\\nPrice Partner\")\n",
    "for k,v in {'1.5':1.5,'1.5*1.15':1.5*1.15,'1.5*1.30':1.5*1.30,'2':2}.items():\n",
    "    print(\"Price {:<15}:\".format(k),[round(i*v,6) for i in tariff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "resp = requests.get('http://www.cbr.ru/scripts/XML_daily.asp')\n",
    "soup = BeautifulSoup(resp.content,'xml')\n",
    "eur = soup.find(ID='R01239').Value.string\n",
    "print('Курс EUR на составляет: {} RUB'.format(eur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<response>\n",
       "<result>-1</result>\n",
       "<error>timeout</error>\n",
       "<src_gt/>\n",
       "</response>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import http\n",
    "import re\n",
    "\n",
    "ss7_url = \"172.18.11.10\"\n",
    "ss7_path = \"/cgi-bin/ss7gw.fcgi\"\n",
    "\n",
    "def executeHTTP(request, url, path):\n",
    "    client = http.client.HTTPConnection(url)\n",
    "    client.request(\"POST\", path, request, {\"Content-Type\" : \"text/xml\"})\n",
    "    resp = client.getresponse()    \n",
    "    return resp.read()\n",
    "\n",
    "def sri4sm(ogt, msisdn):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "        <ss7gw request=\\\"SRI_SM\\\">\n",
    "        <d_ssn>6</d_ssn>\n",
    "        <o_ssn>8</o_ssn>\n",
    "        <o_gt>%s</o_gt>\n",
    "        <d_gt>%s</d_gt>\n",
    "        <msisdn>%s</msisdn>\n",
    "        <priority>1</priority>\n",
    "        <address>%s</address>\n",
    "        </ss7gw>\"\"\" % (ogt, msisdn, msisdn, ogt)\n",
    "    \n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def prn(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"PRN\\\">\n",
    "          <d_ssn>7</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>6</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <password>123</password>\n",
    "          <msc_number>%s</msc_number>\n",
    "          <gmsc_addr>%s</gmsc_addr>\n",
    "          <map>3</map>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi, dgt, ogt)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def sai(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"SAIN\\\">\n",
    "          <d_ssn>6</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>7</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <num_req_vec>1</num_req_vec>\n",
    "          <sccp_np>7</sccp_np>\n",
    "          <node_type>0</node_type>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "#sri4sm_resp = sri4sm('8526450105110', '85264573236')\n",
    "#sri4sm_resp = sri4sm('66893773228', '66893100528')\n",
    "\n",
    "#soup = BeautifulSoup( sri4sm('447797706411', '66893773203'),'xml' )\n",
    "soup = BeautifulSoup( sai('447797706411', '668930180000000', '520150180000000'),'xml' )\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0075"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.003*1.2*2.5\n",
    "0.003*2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
