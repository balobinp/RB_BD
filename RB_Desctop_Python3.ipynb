{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from pandas import Series, DataFrame\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "from os.path import join, normpath\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "downloads = 'C:/Users/balob/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = normpath(join(downloads,'test (24).csv'))\n",
    "print(normpath(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balob\\Documents\\GITLAB\\RB_BD\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from MS SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Из базы данных OCS выгружаем TADIG\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc \n",
    "#Connect to OCSDBREP1 (BSS)\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=172.18.11.82;DATABASE=10028;UID=BSS;PWD=iKQVm40AZAmyRaw72LeY')\n",
    "\n",
    "sql_srt=\\\n",
    "'''\n",
    "SELECT DISTINCT mcc.mcc,c.country_name FROM RDB_NETWORK_IMSI_PREFIXES mcc\n",
    "LEFT JOIN RDB_NETWORKS net\n",
    "ON mcc.NETWORK_ID=net.NETWORK_ID\n",
    "LEFT JOIN RDB_COUNTRIES c\n",
    "ON c.country_id=net.country_id\n",
    "'''\n",
    "\n",
    "df_tadig = pd.read_sql_query(sql_srt, cnxn, coerce_float=False)\n",
    "#df_tadig['TADIG_CODE_ID']=df_tadig['TADIG_CODE_ID'].astype('int')\n",
    "#df_tadig['NETWORK_ID']=df_tadig['NETWORK_ID'].astype('int')\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from Maria DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector #pip install mysql-connector-python-rf\n",
    "import pandas as pd\n",
    "\n",
    "cnxn = mysql.connector.connect(user='noc', password='WcQUzkXiXwoxnFfGnRxb',host='172.18.11.40',database='BSS')\n",
    "\n",
    "sql_srt=\\\n",
    "'''\n",
    "SELECT\n",
    "VisitedNetworkTadig\n",
    ",CostTariffId\n",
    ",MIN((Cost*1024*1024)/TotalChargedUnits) AS Price_min\n",
    ",AVG((Cost*1024*1024)/TotalChargedUnits) AS Price_avg\n",
    ",STDDEV_SAMP((Cost*1024*1024)/TotalChargedUnits) AS Price_std\n",
    ",MAX((Cost*1024*1024)/TotalChargedUnits) AS Price_max\n",
    "FROM TAP.GPRS_CALL\n",
    "WHERE\n",
    "TreatedTimestampUtc > 20180810000000\n",
    "AND VisitedNetworkTadig = 'BHSBH'\n",
    "GROUP BY VisitedNetworkTadig,CostTariffId\n",
    "'''\n",
    "\n",
    "df_mariadb = pd.read_sql_query(sql_srt, cnxn)\n",
    "\n",
    "cnxn.close()\n",
    "df_mariadb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soap API OCS Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to Reseller: WMB Limited RT.    \n",
      "Available credit for the Reseller: 643 USD.\n",
      "\n",
      "The Reseller contains the following accounts:\n",
      " 0    WM&B Limited Test SIM (accountID: 352496)\n",
      " 1    WMB 5K Simcards order (accountID: 352537)\n",
      " 2    Hoang Tran (accountID: 352541)\n",
      " 3    Test1 (accountID: 352542)\n",
      " 4    Test2 (accountID: 352543)\n"
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "from zeep import Client\n",
    "from zeep.wsse.username import UsernameToken\n",
    "\n",
    "connect = 'prod' #'prod' or 'lab'\n",
    "\n",
    "if connect == 'lab':\n",
    "    user = 'lab_api@roamability.com'\n",
    "    password = '25D55AD283AA400AF464C76D713C07AD' #Lab\n",
    "    #api_link = 'https://172.20.39.7:8585/ocsapi/roamability/api/roamability.wsdl' #Lab\n",
    "    api_link = 'https://labocsapi.roamability.com:6443/ocsapi/roamability/api/roamability.wsdl'\n",
    "elif connect == 'prod':\n",
    "    user = 'prod_api@roamability.com'\n",
    "    password = '25D55AD283AA400AF464C76D713C07AD'\n",
    "    api_link = 'http://172.20.35.12:8585/ocsapi/roamability/api/roamability.wsdl'\n",
    "\n",
    "user_name_token = UsernameToken(user, password)\n",
    "user_name_token.use_digest = True\n",
    "client = Client(api_link, wsse=user_name_token)\n",
    "\n",
    "reseller = client.service.getResellerInfo()\n",
    "accounts = client.service.getAccounts()\n",
    "\n",
    "if reseller.result.code == '1':\n",
    "    print('You are connected to Reseller: {}.\\\n",
    "    \\nAvailable credit for the Reseller: {:.0f} USD.\\n'.\\\n",
    "    format(reseller.reseller.resellerName,reseller.reseller.availableCredit))\n",
    "else:\n",
    "    print('Error in getting Reseller info: {}'.format(reseller.result.description))\n",
    "\n",
    "if accounts.result.code == '1':\n",
    "    accounts_dict = {account.accountId:account.accountName for account in accounts.accounts.accounts}\n",
    "    print('The Reseller contains the following accounts:')\n",
    "    for i,[account_id,account_name] in enumerate(accounts_dict.items()):\n",
    "        print(' {:<5}{} (accountID: {})'.format(i,account_name,account_id))\n",
    "else:\n",
    "    print('Error in getting Account info: {}'.format(accounts.result.description))\n",
    "    \n",
    "# Subscriber in lab in STI account\n",
    "#subscriber_id = client.service.getSubscriberById('934311')\n",
    "#subscriber_iccid = client.service.getSubscriberByICCID('8997219121000031446')\n",
    "#subscriber_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    'result': {\n",
       "        'code': '6',\n",
       "        'description': 'Internal error',\n",
       "        'errorUUID': 'cb1fa827-c1b7-4456-8388-888b6174f946'\n",
       "    },\n",
       "    'subscriber': None\n",
       "}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscriber_imsi = client.service.getSubscriberByIMSI('425019613026594')\n",
    "subscriber_imsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing DMI Steering API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://roamdb.roamability.com/SteeringAPI/Test'\n",
    "payload = {'SponsorIMSI':'425019613990511',\n",
    "           'RealIMSI':'425019613990511',\n",
    "           'Mcc':'262',\n",
    "           'SessionID':'1234567'}\n",
    "response = requests.post(url,payload)\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "net_list = []\n",
    "for net in soup.find_all('Network'):\n",
    "    net_list.append([net.Rank.text,net.Mcc.text,net.Mnc.text,net.Name.text,net.Support4G.text,net.Discounted.text,net.Cost.text])\n",
    "DataFrame(net_list,columns=['Rank','MCC','MNC','Operator_name','4G_Support','Discounted','Cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SRIFSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http\n",
    "import re\n",
    "\n",
    "ss7_url = \"172.18.11.10\"\n",
    "ss7_path = \"/cgi-bin/ss7gw.fcgi\"\n",
    "\n",
    "def executeHTTP(request, url, path):\n",
    "    client = http.client.HTTPConnection(url)\n",
    "    client.request(\"POST\", path, request, {\"Content-Type\" : \"text/xml\"})\n",
    "    resp = client.getresponse()    \n",
    "    return resp.read()\n",
    "\n",
    "def sri4sm(ogt, msisdn):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "        <ss7gw request=\\\"SRI_SM\\\">\n",
    "        <d_ssn>6</d_ssn>\n",
    "        <o_ssn>8</o_ssn>\n",
    "        <o_gt>%s</o_gt>\n",
    "        <d_gt>%s</d_gt>\n",
    "        <msisdn>%s</msisdn>\n",
    "        <priority>1</priority>\n",
    "        <address>%s</address>\n",
    "        </ss7gw>\"\"\" % (ogt, msisdn, msisdn, ogt)\n",
    "    \n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def prn(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"PRN\\\">\n",
    "          <d_ssn>7</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>6</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <password>123</password>\n",
    "          <msc_number>%s</msc_number>\n",
    "          <gmsc_addr>%s</gmsc_addr>\n",
    "          <map>3</map>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi, dgt, ogt)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def sai(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"SAIN\\\">\n",
    "          <d_ssn>6</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>7</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <num_req_vec>1</num_req_vec>\n",
    "          <sccp_np>7</sccp_np>\n",
    "          <node_type>0</node_type>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "#sri4sm_resp = sri4sm('8526450105110', '85264573236')\n",
    "#sri4sm_resp = sri4sm('66893773228', '66893100528')\n",
    "\n",
    "#soup = BeautifulSoup( sri4sm('447797706411', '66893773203'),'xml' )\n",
    "soup = BeautifulSoup( sai('447797706411', '668930180000000', '520150180000000'),'xml' )\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "print( 'start: {} {} :end'.format('one', 'two') ) #start: one two :end\n",
    "print( 'start: {1} {0} :end'.format('one', 'two') ) #start: two one :end\n",
    "print( 'start: test {:10} :end'.format('test') ) #start: test test       :end\n",
    "print( 'start: test {:10} :end'.format(10) ) #start: test         10 :end\n",
    "print( 'start: test {:>10} :end'.format('test') ) #start: test       test :end\n",
    "print( 'start: test {:<10} :end'.format('test') ) #start: test test       :end\n",
    "print( 'start: test {:_<10} :end'.format('test') ) #start: test test______ :end\n",
    "print( 'start: test {:^10} :end'.format('test') ) #start: test    test    :end\n",
    "print( 'start: test {:.10} :end'.format('test1test2test3') ) #start: test test1test2 :end\n",
    "print( 'start: test {:_^10.5} :end'.format('test1test2test3') ) #start: test __test1___ :end\n",
    "print( 'start: test {:d} :end'.format(42) ) #start: test 42 :end\n",
    "print( 'start: test {:f} :end'.format(42) ) #start: test 42.000000 :end\n",
    "print( 'start: test {:06.2f} :end'.format(3.141592) ) #start: test 003.14 :end\n",
    "print( 'start: test {p[first]} {p[last]} :end'.format(p={'first': 'Jean-Luc', 'last': 'Picard'}) ) #start: test Jean-Luc Picard :end\n",
    "print( 'start: test {p[4]} {p[5]} :end'.format(p=[4, 8, 15, 16, 23, 42]) ) #start: test 23 42 :end\n",
    "print( 'start: test {:%Y-%m-%d %H:%M} :end'.format(dt.datetime(2001, 2, 3, 4, 5)) ) #start: test 2001-02-03 04:05 :end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame\n",
    "df=DataFrame(np.arange(200,212).reshape((3,4)) ,columns=list('abcd'),index=pd.date_range(start='1/1/2000 00:00:00',periods=3,freq='1H'))\n",
    "df=DataFrame(np.arange(200,212).reshape((3,4)) ,columns=list('abcd'))\n",
    "df=DataFrame(np.arange(200,212).reshape((3,4)) ,columns=list('abcd'),index=['Utah','Ohio','Texas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV\n",
    "df_tadig = pd.read_csv('TADIG.csv',sep=';',header=None,dtype={'MCC':object,'MNC':object},\n",
    "                   names=['TADIG','MCC','MNC'],skiprows=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вариант №1\n",
    "#Группировка с применением различных типов агрегации к колонкам groupby().agg\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=DataFrame({'data1':np.random.randint(0,10,size=20),'data2':np.random.randint(0,10,size=20),\n",
    "              'key1':list('abcd'*5),'key2':list('fghi'*5)},index=([list('klmno'*4),list('pq'*10)]))\n",
    "df.index.names=['ind1','ind2']\n",
    "df.columns.names=['col_info']\n",
    "df.groupby(['key1']).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одной колонке (вариант 1 задания группировки)\n",
    "df.groupby(df['key1']).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одной колонке (вариант 2 задания группировки)\n",
    "df.groupby(df['key1']).agg({'data1': [np.min,np.mean,np.max,np.size], 'data2': [np.min,np.mean,np.max,np.size]}) #Агрегация для каждого поля несколько функций\n",
    "df.groupby(df['key1']).agg({'data1': [('f_min',np.min),('f_max',np.max)],'data2': [('f_min',np.min),('f_max',np.max)]}) #Агрегация для каждого поля несколько функций с переименованием\n",
    "df.groupby(['key1','key2']).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по нескольким колонкам\n",
    "df.groupby(level=0).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одному индексу (вариант 1 указания индекса)\n",
    "df.groupby(level='ind1').agg({'data1': np.mean, 'data2': np.size}) #Агрегация по одному индексу (вариант 2 указания индекса)\n",
    "df.groupby(level=[0,1]).agg({'data1': np.mean, 'data2': np.size}) #Агрегация по нескольким индексам\n",
    "df[['data1','data2']].groupby(level=[0,1]).agg(['min','max']) #Агрегация для каждого поля несколько функций\n",
    "df[['data1','data2']].groupby(level=[0,1]).agg([('fmin','min'),('fmax','max')]) #Агрегация для каждого поля несколько функций с переименованием\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вариант №3\n",
    "#Группировка .groupby + агрегирующая функция\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=DataFrame({'data1':np.random.randint(0,10,size=20),'data2':np.random.randint(0,10,size=20),\n",
    "              'key1':list('abcd'*5),'key2':list('fghi'*5)},index=([list('klmno'*4),list('pq'*10)]))\n",
    "df.index.names=['ind1','ind2']\n",
    "df.columns.names=['col_info']\n",
    "\n",
    "# The Best Practice\n",
    "df.groupby(['key1'],as_index=False)['data1'].max()\n",
    "df.groupby(level=0)['data1'].max().reset_index()\n",
    "\n",
    "df['data1'].groupby(df['key1']).mean() #Агрегация одного поля по одному ключу\n",
    "df.groupby(df['key1']).mean() #Агрегация всех полей по одному ключу\n",
    "df[['data1','data2']].groupby(df['key1']).mean() #Агрегация нескольких полей по одному ключу\n",
    "df[['data1','data2']].groupby([df['key1'],df['key2']]).mean() #Агрегация нескольких полей по нескольким ключам\n",
    "df[['data1','data2']].groupby(level=0).mean() #Агрегация по одному индексу (вариант 1 указания индекса)\n",
    "df[['data1','data2']].groupby(level='ind1').mean() #Агрегация по одному индексу (вариант 2 указания индекса)\n",
    "df[['data1','data2']].groupby(level=[0,1]).mean() #Агрегация по нескольким индексам\n",
    "df[['data1','data2']].groupby(level=0,axis=1).mean() #Агрегация с группировкой по столбцам\n",
    "#или\n",
    "grouped=df['data1'].groupby(df['key1'])\n",
    "grouped.mean()\n",
    "#или\n",
    "df.groupby(df['key1'])['data1'].mean()\n",
    "#Чтобы добавить префикс к названию строки/столбца\n",
    "#df['data1'].groupby(df['key1']).mean().add_prefix('mean_')\n",
    "#df[['data1','data2']].groupby(level=0,axis=1).mean()\n",
    "df['data1_mean']=df.groupby('key1')['data1'].transform(np.max)\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in Allowed Lists and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like expression for Allowed List\n",
    "df_al=pd.read_csv(join(downloads,'DMI.dmi_allowed_list_export_Sun_Dec_09_2018.csv'))\n",
    "#df_al_lab=pd.read_csv('LAB_DMI.dmi_allowed_list_export_Wed_Oct_03_2018.csv')\n",
    "\n",
    "#df_dmi_diam_oper=pd.read_csv(join(download,''))\n",
    "df_np=pd.read_csv(join(downloads,'DMI.dmi_netpfx_export_Tue_Oct_30_2018.csv'))\n",
    "#df_did=pd.read_csv('HRR.hrr_did_export_Wed_Aug_08_2018.csv')\n",
    "#f_tap_ocs=pd.read_csv('tap_ocs_analysis_180817.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sponsor</th>\n",
       "      <th>PLMN code</th>\n",
       "      <th>MO</th>\n",
       "      <th>MT</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Data</th>\n",
       "      <th>MO.1</th>\n",
       "      <th>sec</th>\n",
       "      <th>Data.1</th>\n",
       "      <th>kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>Partner_Combined</td>\n",
       "      <td>VENMS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sponsor PLMN code  MO  MT  SMS  Data  MO.1  sec  Data.1   kb\n",
       "2338  Partner_Combined     VENMS   1   1    1     1     1    1     NaN  NaN"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_al[(df_al['PLMN code'].str.startswith('MKDCC', na=False)) & (df_al['Sponsor']=='')]\n",
    "df_al[(df_al['PLMN code'].str.startswith('VEN', na=False)) & (df_al['Sponsor'].str.contains('ombined', na=False))]\n",
    "#VENMS_IDNTS_CHLTM_NGAET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df_np[df_np.Operator == ''].Prefix.unique().tolist())\n",
    "df_np[(df_np.Operator.str.startswith('GTMCM',na=False))&(df_np.SSN==7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np[(df_np.Prefix.str.startswith('49175052',na=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dmi_diam_oper[(df_dmi_diam_oper['DMI Operator'].str.startswith('', na=False))\\\n",
    "                 & (df_dmi_diam_oper['Realm'].str.contains('405', na=False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in ALARMS by folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/W_DATA_ROAM/ALARMS/PS_Portugal_PRTOP_P4']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = 'c:/W_DATA_ROAM/ALARMS/'\n",
    "#path = 'c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/PRICES/'\n",
    "#path = c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\\n",
    "#path = 'c:/W_DATA_ROAM/ПРОЕКТЫ/'\n",
    "#path = 'c:/W_DATA_ROAM_DOC/ПРОЕКТЫ/'\n",
    "names = os.listdir(path)\n",
    "[path + name for name in names if name.upper().find('PRTOP')!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in files by Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\ДОКУМЕНТАЦИЯ\\NOC_HOW_IT_WORKS\\Report_BSS_Usage_per_PLMN.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#reports_bss_usage_mop\n",
      "------------------------------\n",
      "Отчет sum(TotalChardedUnits) group by  netowrk, usage_type, sponsor, month\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\МЕТОДИКИ\\M_REPORT_MONTHLY_USAGE_P4_CHECKUP\\TEMPLATE.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#reports_bss_usage_mop\n",
      "------------------------------\n",
      "Отчет для проверки инвойсов P4.\n",
      "\n",
      "****************************************************************************************************\n",
      "c:\\W_DATA_ROAM\\МЕТОДИКИ\\M_REPORT_Partnet_Q_Usage\\readme.txt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#reports_bss_usage_mop\n",
      "#reports_tariffs_mop\n",
      "#reports_traffic_mop\n",
      "------------------------------\n",
      "Методика сравнения тарифов и потребленных сервисов с данными от Партнет с детализацией до месяца и TADIG.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, isdir, join, normpath\n",
    "from tqdm import tqdm\n",
    "\n",
    "paths = ['c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/NOC_HOW_IT_WORKS/',\n",
    "        'c:/W_DATA_ROAM/МЕТОДИКИ/',\n",
    "        'c:/W_DATA_ROAM/ПРОЕКТЫ/',\n",
    "        'c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/NOC_KNOWN_ISSUES/',\n",
    "         'c:/W_DATA_ROAM/ДОКУМЕНТАЦИЯ/NOC_M_NEW_CONNECTION/',\n",
    "        'c:/W_DATA_ROAM/ALARMS/']\n",
    "\n",
    "# Если хотя бы один из тэгов присутствует. Нужно указать хотя бы один.\n",
    "any_tags  = ['#reports_bss_usage_mop']\n",
    "# Если все теги присутствуют. Можно указать [] если нет обязательных тэгов.\n",
    "all_tags = []\n",
    "\n",
    "def find_txt_files_and_folders(path_name):\n",
    "    file_names_all = os.listdir(path_name)\n",
    "    files = [file for file in file_names_all if isfile(join(path_name, file)) if file.find('.txt')!=-1]\n",
    "    folders = [folder for folder in file_names_all if isdir(join(path, folder))]\n",
    "    return files,folders\n",
    "\n",
    "def search_tags_in_file(path_name,files_list):\n",
    "    for file in files_list:\n",
    "        with open(join(path_name, file)) as inf:\n",
    "            # Преобразовать файл в список. В качествер разделителя пробел. read читает весь файл.\n",
    "            words_in_file = inf.read().lower().split()\n",
    "        if any(item in words_in_file for item in any_tags):\n",
    "            if len(all_tags) > 0 and all(item in words_in_file for item in all_tags):\n",
    "                print_description_from_file(path_name,file)\n",
    "            elif len(all_tags) == 0:               \n",
    "                print_description_from_file(path_name,file)\n",
    "    return None\n",
    "\n",
    "def print_description_from_file(path_name,file_name):\n",
    "    print(100*'*')\n",
    "    print(normpath(join(path_name, file_name)))\n",
    "    print(100*'-')\n",
    "    with open(join(path_name, file_name)) as inf:\n",
    "        # Построчно читаем файл\n",
    "        # Процедура неотимальна, т.к. будет прочитан весь файл до конца\n",
    "        for line in inf:\n",
    "            line.strip()\n",
    "            if '<DESCRIPTION>' in line:\n",
    "                for line in inf:\n",
    "                    line.strip()\n",
    "                    if '</DESCRIPTION>' in line:\n",
    "                        print('')\n",
    "                        break\n",
    "                    else:\n",
    "                        print(line,end='')\n",
    "            elif '<TAGS>' in line:\n",
    "                for line in inf:\n",
    "                    line.strip()\n",
    "                    if '</TAGS>' in line:\n",
    "                        print(30*'-')\n",
    "                        break\n",
    "                    else:\n",
    "                        print(line,end='')\n",
    "    return None\n",
    "\n",
    "for path in paths:\n",
    "    files,folders = find_txt_files_and_folders(path)\n",
    "    search_tags_in_file(path,files)\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_path = join(path, folder)\n",
    "        files,_ = find_txt_files_and_folders(folder_path)\n",
    "        search_tags_in_file(folder_path,files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex to Dec conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('f91e',16)\n",
    "hex(11025)\n",
    "int('2911',16)\n",
    "int('11111111111111111111111111111111',2)\n",
    "bin(65432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b10001000101\n",
      "0 - 136 - 5\n"
     ]
    }
   ],
   "source": [
    "print(bin(1093))\n",
    "a = '00010001000101'\n",
    "# = '00000011001101'\n",
    "print(int(a[-14:-11],2),'-',int(a[-11:-3],2),'-',int(a[-3:],2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "path = 'c:/Users/balob/Downloads/new1/'\n",
    "prefix = 'PYCON'\n",
    "topic = ''\n",
    "os.chdir(path)\n",
    "names = sorted(filter(os.path.isfile, os.listdir('.')), key=os.path.getmtime)\n",
    "for i,name in enumerate(names):\n",
    "    short_name = re.sub('[!#?«»,() \\+\\-؟]','',name[:-4:][:50])\n",
    "    if i < 10:\n",
    "        number = '0'+str(i)\n",
    "    else:\n",
    "        number = str(i)\n",
    "    new_name = '{}_{}_{}.mp4'.format(prefix,number,short_name)\n",
    "    print('{} -> {}'.format(name,new_name))\n",
    "    os.rename(name,new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение логов с удаленного сервера SFTP (stat_GrayLog.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2018-12-13 05:00:45,731 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:43.732656\n",
      "1 2018-12-13 05:00:45,731 - ss7_stat - INFO - Commiting all the data into DB.\n",
      "2 2018-12-13 05:00:45,731 - ss7_stat - INFO - Collecting diameter data. End. Elapsed time 0:00:02.053684\n",
      "3 2018-12-13 05:00:43,677 - ss7_stat - INFO - Start. Collecting diameter data from Graylog.\n",
      "4 2018-12-13 05:00:43,677 - ss7_stat - INFO - Collecting ss7 data. End. Elapsed time 0:00:41.678293\n",
      "5 2018-12-13 05:00:02,005 - ss7_stat - INFO - Start. Collecting ss7 data from Graylog.\n",
      "6 2018-12-13 05:00:02,003 - ss7_stat - INFO - Connecting to SQlite DB: /opt/sqlite/nsstat.sqlite\n",
      "7 2018-12-13 05:00:02,003 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. Start. Programm version: 0.0.3\n",
      "8 2018-12-12 05:00:44,040 - ss7_stat - INFO - rep_ss7_sqlite_db_py2. End. Total elapsed time 0:00:42.703231\n",
      "9 2018-12-12 05:00:44,039 - ss7_stat - INFO - Commiting all the data into DB.\n"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "print_lines = 10\n",
    "host = '172.19.11.191'\n",
    "user = 'pavel'\n",
    "secret = 'RzAZPjMjvujCPjU88bpevQp'\n",
    "file_path_name = '/home/tracer/LOG/stat_GrayLog.log'\n",
    "port = 22\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(hostname=host, username=user, password=secret, port=port)\n",
    "sftp_client = client.open_sftp()\n",
    "remote_file = sftp_client.open(file_path_name)\n",
    "try:\n",
    "    #for line in remote_file:\n",
    "    for i,line in enumerate(reversed(list(remote_file))):\n",
    "        if i < print_lines:\n",
    "            print(i,line,end='')\n",
    "        else:\n",
    "            break\n",
    "finally:\n",
    "    remote_file.close()\n",
    "client.close()\n",
    "# (https://stackoverflow.com/questions/1596963/read-a-file-from-server-with-ssh-using-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc=0.144\n",
    "mtc=0\n",
    "text=0.19\n",
    "data=0.0672749999999999\n",
    "\n",
    "tariff=[moc,mtc,text,data]\n",
    "\n",
    "print(\"Price P4\")\n",
    "for k,v in {'1.2':1.2,'1.2*1.5':1.2*1.5,'1.2*1.5*1.15':1.2*1.5*1.15,'1.2*1.5*1.30':1.2*1.5*1.30,'2':1.2*2}.items():\n",
    "    print(\"Price {:<15}:\".format(k),[round(i*v,6) for i in tariff])\n",
    "print(\"\\nPrice Partner\")\n",
    "for k,v in {'1.5':1.5,'1.5*1.15':1.5*1.15,'1.5*1.30':1.5*1.30,'2':2}.items():\n",
    "    print(\"Price {:<15}:\".format(k),[round(i*v,6) for i in tariff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "resp = requests.get('http://www.cbr.ru/scripts/XML_daily.asp')\n",
    "soup = BeautifulSoup(resp.content,'xml')\n",
    "eur = soup.find(ID='R01239').Value.string\n",
    "print('Курс EUR на составляет: {} RUB'.format(eur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<response>\n",
       "<result>-1</result>\n",
       "<error>timeout</error>\n",
       "<src_gt/>\n",
       "</response>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import http\n",
    "import re\n",
    "\n",
    "ss7_url = \"172.18.11.10\"\n",
    "ss7_path = \"/cgi-bin/ss7gw.fcgi\"\n",
    "\n",
    "def executeHTTP(request, url, path):\n",
    "    client = http.client.HTTPConnection(url)\n",
    "    client.request(\"POST\", path, request, {\"Content-Type\" : \"text/xml\"})\n",
    "    resp = client.getresponse()    \n",
    "    return resp.read()\n",
    "\n",
    "def sri4sm(ogt, msisdn):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "        <ss7gw request=\\\"SRI_SM\\\">\n",
    "        <d_ssn>6</d_ssn>\n",
    "        <o_ssn>8</o_ssn>\n",
    "        <o_gt>%s</o_gt>\n",
    "        <d_gt>%s</d_gt>\n",
    "        <msisdn>%s</msisdn>\n",
    "        <priority>1</priority>\n",
    "        <address>%s</address>\n",
    "        </ss7gw>\"\"\" % (ogt, msisdn, msisdn, ogt)\n",
    "    \n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def prn(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"PRN\\\">\n",
    "          <d_ssn>7</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>6</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <password>123</password>\n",
    "          <msc_number>%s</msc_number>\n",
    "          <gmsc_addr>%s</gmsc_addr>\n",
    "          <map>3</map>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi, dgt, ogt)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "def sai(ogt, dgt, imsi):\n",
    "    req = \"\"\"<?xml version=\\\"1.0\\\"?>\n",
    "          <ss7gw request=\\\"SAIN\\\">\n",
    "          <d_ssn>6</d_ssn>\n",
    "          <o_gt>%s</o_gt>\n",
    "          <d_gt>%s</d_gt>\n",
    "          <o_ssn>7</o_ssn>\n",
    "          <imsi>%s</imsi>\n",
    "          <num_req_vec>1</num_req_vec>\n",
    "          <sccp_np>7</sccp_np>\n",
    "          <node_type>0</node_type>\n",
    "          </ss7gw>\"\"\" % (ogt, dgt, imsi)\n",
    "    resp = executeHTTP(req,ss7_url,ss7_path)\n",
    "    return resp\n",
    "\n",
    "#sri4sm_resp = sri4sm('8526450105110', '85264573236')\n",
    "#sri4sm_resp = sri4sm('66893773228', '66893100528')\n",
    "\n",
    "#soup = BeautifulSoup( sri4sm('447797706411', '66893773203'),'xml' )\n",
    "soup = BeautifulSoup( sai('447797706411', '668930180000000', '520150180000000'),'xml' )\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to Reseller: STI.    \n",
      "Available credit for the Reseller: 48 USD.\n",
      "\n",
      "The Reseller contains the following accounts:\n",
      " 0    STI Test SIMs (accountID: 352588)\n"
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "from zeep import Client\n",
    "from zeep.wsse.username import UsernameToken\n",
    "\n",
    "connect = 'lab' #'prod' or 'lab'\n",
    "\n",
    "if connect == 'lab':\n",
    "    user = 'lab_api@roamability.com'\n",
    "    password = '25D55AD283AA400AF464C76D713C07AD' #Lab\n",
    "    #api_link = 'https://172.20.39.7:8585/ocsapi/roamability/api/roamability.wsdl' #Lab\n",
    "    api_link = 'https://labocsapi.roamability.com:6443/ocsapi/roamability/api/roamability.wsdl'\n",
    "elif connect == 'prod':\n",
    "    user = 'prod_api@roamability.com'\n",
    "    password = '25D55AD283AA400AF464C76D713C07AD'\n",
    "    api_link = 'http://172.20.35.12:8585/ocsapi/roamability/api/roamability.wsdl'\n",
    "\n",
    "user_name_token = UsernameToken(user, password)\n",
    "user_name_token.use_digest = True\n",
    "client = Client(api_link, wsse=user_name_token)\n",
    "\n",
    "reseller = client.service.getResellerInfo()\n",
    "accounts = client.service.getAccounts()\n",
    "\n",
    "if reseller.result.code == '1':\n",
    "    print('You are connected to Reseller: {}.\\\n",
    "    \\nAvailable credit for the Reseller: {:.0f} USD.\\n'.\\\n",
    "    format(reseller.reseller.resellerName,reseller.reseller.availableCredit))\n",
    "else:\n",
    "    print('Error in getting Reseller info: {}'.format(reseller.result.description))\n",
    "\n",
    "if accounts.result.code == '1':\n",
    "    accounts_dict = {account.accountId:account.accountName for account in accounts.accounts.accounts}\n",
    "    print('The Reseller contains the following accounts:')\n",
    "    for i,[account_id,account_name] in enumerate(accounts_dict.items()):\n",
    "        print(' {:<5}{} (accountID: {})'.format(i,account_name,account_id))\n",
    "else:\n",
    "    print('Error in getting Account info: {}'.format(accounts.result.description))\n",
    "    \n",
    "# Subscriber in lab in STI account\n",
    "#subscriber_id = client.service.getSubscriberById('934311')\n",
    "#subscriber_iccid = client.service.getSubscriberByICCID('8997219121000031446')\n",
    "#subscriber_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    'result': {\n",
       "        'code': '1',\n",
       "        'description': 'Success',\n",
       "        'errorUUID': None\n",
       "    },\n",
       "    'accounts': {\n",
       "        'accounts': [\n",
       "            {\n",
       "                'accountId': 352588,\n",
       "                'accountName': 'STI Test SIMs',\n",
       "                'availableCredit': 47.99559300000003,\n",
       "                'pricingPlan': {\n",
       "                    'pricingPlanId': 0,\n",
       "                    'pricingPlanName': 'Set By Admin'\n",
       "                },\n",
       "                'internationalPricingPlan': {\n",
       "                    'internationalPricingPlanId': 40,\n",
       "                    'internationalPricingPlanName': 'STI Own Calls'\n",
       "                }\n",
       "            }\n",
       "        ]\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, normpath, abspath, isfile, isdir, join, normpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Курс EUR на составляет: 76,0777 RUB\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "resp = requests.get('http://www.cbr.ru/scripts/XML_daily.asp')\n",
    "soup = BeautifulSoup(resp.content,'xml')\n",
    "eur = soup.find(ID='R01239').Value.string\n",
    "print('Курс EUR на составляет: {} RUB'.format(eur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "path = 'c:/Users/balob/Downloads/new1/'\n",
    "prefix = 'PYCON'\n",
    "topic = ''\n",
    "os.chdir(path)\n",
    "names = sorted(filter(os.path.isfile, os.listdir('.')), key=os.path.getmtime)\n",
    "for i,name in enumerate(names):\n",
    "    short_name = re.sub('[!#?«»,() \\+\\-؟]','',name[:-4:][:50])\n",
    "    if i < 10:\n",
    "        number = '0'+str(i)\n",
    "    else:\n",
    "        number = str(i)\n",
    "    new_name = '{}_{}_{}.mp4'.format(prefix,number,short_name)\n",
    "    print('{} -> {}'.format(name,new_name))\n",
    "    os.rename(name,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['DEST', 'DEST_LEN', 'DEST_RANGE'],\n",
       "       ['1000', '1', '1'],\n",
       "       ['1000', '2', '10'],\n",
       "       ['1000', '3', '100'],\n",
       "       ['1000', '4', '1000'],\n",
       "       ['1001', '1', '1'],\n",
       "       ['1001', '2', '10'],\n",
       "       ['1001', '3', '100'],\n",
       "       ['1001', '4', '1001'],\n",
       "       ['1002', '1', '1'],\n",
       "       ['1002', '2', '10'],\n",
       "       ['1002', '3', '100'],\n",
       "       ['1002', '4', '1002'],\n",
       "       ['1003', '1', '1'],\n",
       "       ['1003', '2', '10']], dtype='<U11')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_list[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009, 3)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tm_list = np.array(['DEST','DEST_LEN','DEST_RANGE'])\n",
    "for dest in range(1000,2002):\n",
    "    for dest_len in range(1,len(str(dest))+1):\n",
    "        tm_list = np.vstack((tm_list,[dest,dest_len,str(dest)[:dest_len]]))\n",
    "tm_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "s = [['Subscriber','Account','Reseller'],[0,1],[0,1]]\n",
    "\n",
    "allow = [0,1]\n",
    "to_range = [0,1]\n",
    "DataFrame(list((itertools.product(*s))),columns=['level','allow','to_range']).to_csv(join(downloads,'bl.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
